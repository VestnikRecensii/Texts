# Философская проблема искусственного интеллекта и ее эволюция

## История ИИ

Уже в древнем мире были предания о разумных механических существах. Например, в греческой мифологии бог Гефест создал из бронзы гиганта по имени Талос и наделил его душой. В китайском писании третьего века до нашей эры есть история изобретателя Янь Ши, который представляет королю механического человека, способного ходить и петь "чистейшим голосом".

Разложить сознание по вычислительным терминам в 17 веке пытался Готфрид Вильгельм фон Лейбниц. В 1673 году он построил механический арифмометр, устройство, которое могло не только складывать и вычитать, но и умножать и делить. Дальнейшие открытия в алгебре дали возможность описывать математическим языком широкий круг идей и открыли большой спектр возможностей для "мыслящих" машин.

Работа британского математика Алана Тьюринга (1912-1954) дала начало открытиям в области ИИ. Еще в 1947 году он публично говорил о "машине, которая может учиться на собственном опыте". В 1950 он придумал метод для определения способности машины мыслить как человек, известный как тест Тьюринга.

Термин ИИ придумал в 1956 году Джон Маккарти, 28-летний профессор Дартмутского колледжа, на конференции по машинному обучению, организованной Маккарти и другими профессорами из Дартмута. ("Гарри с грустью подумал о Дартмутском семинаре 1956-го года, первой в истории конференции по вопросам искусственного интеллекта. В качестве ключевых вопросов участники выделили: понимание языка, самообучение и самосовершенствование компьютеров. Они абсолютно серьёзно предполагали, что десять учёных смогут достичь существенных результатов по данным вопросам, если будут работать вместе в течение двух месяцев." Элиезер Юдковски "Гарри Поттер и методы рационального мышления". Аналогичная история продолжается с термоядерным синтезом, который наверняка будет готов через 20 лет. И так с 1950-х годов).

Не только математики интересовались искусственным интеллектом. Фрэнк Розенблатт (1928-1971) первым использовал естественные науки в этой области. В 1958 году он изобрел перцептрон — электронное устройство, которое имитирует нейронные сети в человеческом мозге. Газета The New York Times назвала его технологию "зародышем электронного компьютера", который должен был "уметь ходить, говорить, видеть, писать, воспроизводить себя и осознавать свое существование".

### Успехи ИИ

- Ты всего лишь машина, только имитация жизни. Разве может робот сочинить симфонию, сделать шедевр?
- А ты сможешь, умник?
"Я, робот"

За последние два-три десятилетия появилось много примеров превосходства ИИ над человеком. В 1997 году суперкомпьютер Deep Blue победил чемпиона мира по шахматам Гарри Каспарова. В 2011 году компьютерная система Watson выиграла 1 миллион долларов в американском телевизионном шоу "Своя игра". В 2015 году система AlphaGo от Google DeepMind разгромила в настольной игре Го лучшего европейского игрока Фань Хуэя, а в 2016 она же обыграла более титулованного игрока Ли Седоля. В 2018 Google DeepMind выпустили AlphaStar - ИИ для игры в StarCraft 2, который в 2019 достиг высшего внутриигрового ранга лиги — грандмастера.

В 2022 компанией OpenAI разработан ChatGPT - чат-бот с искусственным интеллектом, способный работать в диалоговом режиме, отвечая на запросы на естественных языках. Он может писать и отлаживать компьютерные программы, имитировать разные стили текста, писать бизнес-презентации, сочинять музыку, телеспектакли, сказки и сочинения, отвечать на вопросы теста (иногда даже лучше среднего человека-испытателя), писать стихи и тексты песен, переводить и обобщать текст, эмулировать систему Linux и т.д.

### Угрозы

В 2015 году британский физик Стивен Хокинг заявил, что ИИ уже настолько развит, что "в какой-то момент в течение следующих 100 лет" компьютеры превзойдут людей. "Мы должны быть уверены, что цели компьютеров совпадают с нашими", – сказал Хокинг.

А совсем недавно, 2 мая 2023 Джеффри Хинтон, руководитель исследовательского подразделения Google по искусственному интеллекту, подал в отставку. Он считает, что в долгосрочной перспективе ИИ устранит не только всю рутинную работу, но и, возможно, само человечество. "Эта штука действительно может стать умнее людей, и это произойдет не через 30-50 лет, а значительно быстрее", — заявил он, объясняя мотивы своего поступка.

## Проблемы ИИ

### Что можно считать интеллектом и может ли машина демонстрировать общий интеллект и мыслить?

Интеллект (от лат. intellectus "восприятие", "разумение", "понимание") - в общем смысле способность мыслить; в гносеологии (учение о познании) – способность к опосредованному, абстрактному познанию, включающая в себя такие функции, как сравнение, абстрагирование (т.е. от­вле­че­ние от тех или иных ха­рак­те­ри­стик объекта для их из­би­ра­тель­но­го анализа), образование понятий, суждение, умозаключение; в психологии – рациональное, подчиненное законам логики мышление.

Еще одно определение интеллекта - это способность к уже упомянутой абстракции, логике, пониманию, самосознанию, обучению, эмоциональным знаниям, рассуждениям, планированию, творчеству, критическому мышлению и решению проблем. Или коротко - способность воспринимать или делать выводы и сохранять их как знание, которое можно применить для адаптивного поведения в среде или контексте.

Вопрос. Можно ли создать машину, которая сможет решать все задачи, решаемые людьми с помощью своего интеллекта? И действительно ли машина думает подобно человеку, а не просто выдает результаты, которые кажутся результатом мышления?

Основная позиция большинства исследователей ИИ резюмируется в следующем заявлении, появившемся на уже упомянутой конференции в Дартмуте в 1956 году: "Каждый аспект обучения или любую другую характеристику интеллекта можно описать настолько точно, что можно создать машину для их моделирования".

Аргументы против этого тезиса должны показать, что создание работающей системы искусственного интеллекта невозможно, поскольку существует некоторый практический предел возможностей компьютеров или же существует какое-то особое качество человеческого разума, необходимое для разумного поведения, которое не может быть воспроизведено машиной. Аргументы в пользу тезиса должны показать, что такая система возможна.

Первый шаг к ответу на поставленный вопрос — четко определить границы "интеллекта".

#### Интеллект

Первый вариант определения интеллекта - тест Тьюринга.

Если машина может ответить на любой заданный ей вопрос, используя те же слова, что и обычный человек, то мы можем назвать эту машину разумной. Критика теста Тьюринга заключается в том, что он измеряет только "человечность", а не "интеллект" поведения машины (человеческое поведение и интеллектуальное поведение не совсем одно и то же).

Второй вариант. Интеллект как достижение целей.

Исследования ИИ двадцать первого века определяют интеллект с точки зрения целенаправленного поведения. Интеллект как набор задач, которые машина должна решить: чем больше задач она может решить и чем лучше ее решения, тем она умнее. Автор термина ИИ Джон Маккарти определил интеллект как "вычислительную часть способности достигать целей в мире".

Стюарт Рассел и Питер Норвиг формализовали это определение, используя абстрактных интеллектуальных агентов. "Агент" — это то, что воспринимает и действует в окружающей среде. "Показатель эффективности" определяет, что считается успехом агента. "Если агент действует так, чтобы максимизировать ожидаемое значение показателя эффективности на основе прошлого опыта и знаний, то он разумен".

Определения, подобные этому, пытаются уловить сущность интеллекта. У них есть преимущество перед тестом Тьюринга: они не проверяют неразумные человеческие черты, такие как опечатки. У них есть серьезный недостаток, заключающийся в том, что они не могут провести различие между "вещами, которые мыслят" и "вещами, которые не мыслят". Согласно этому определению, даже термостат обладает элементарным интеллектом.

#### Аргументы в пользу того, что машина может демонстрировать общий интеллект

- Мозг можно смоделировать. Хьюберт Дрейфус описывает этот аргумент так: "Если нервная система подчиняется законам физики и химии, а у нас есть все основания предполагать, что она подчиняется, то мы должны быть в состоянии воспроизводить поведение нервной системы с помощью некоторого физического устройства". Даже резкие критики ИИ согласны с тем, что симуляция мозга теоретически возможна. Доведение определения до предела приводит к выводу, что любой процесс вообще технически может считаться "вычислением". "Мы хотели узнать, что отличает разум от термостатов и печени", — пишет Джон Сёрл.

- Человеческое мышление — это обработка символов. В 1963 году Аллен Ньюэлл и Герберт А. Саймон предположили, что "манипулирование символами" является сущностью как человеческого, так и машинного интеллекта. Они написали: "Система физических символов обладает необходимыми и достаточными средствами общего разумного действия". Это очень смелое утверждение: оно подразумевает и то, что человеческое мышление является разновидностью манипуляции с символами (поскольку для разума необходима система символов), и что машины могут быть разумными (поскольку для интеллекта достаточно системы символов).

Существуют аргументы против этого тезиса. Эти аргументы показывают, что человеческое мышление не состоит исключительно из манипуляций с символами высокого уровня. Они не утверждают, что искусственный интеллект невозможен, а только то, что требуется нечто большее, чем просто обработка символов.

- Гёделевские антимеханистические аргументы. В 1931 году Курт Гёдель с помощью теоремы о неполноте доказал, что всегда можно построить утверждение, которое не может доказать данная непротиворечивая формальная система логики (например, программа манипулирования символами высокого уровня). Несмотря на то, что построенное утверждение является истинным утверждением, оно недоказуемо в данной системе. 

Например, система человеческих математиков одновременно непротиворечива (полностью свободна от ошибок) и полностью верит в свою собственную непротиворечивость, и может делать все логические выводы, следующие из ее собственной непротиворечивости, включая веру в утверждение Гёделя. Это доказанно невозможно для машины Тьюринга (т.н. Проблема остановки), следовательно, человеческое мышление слишком мощно, чтобы его можно было реализовать на машине Тьюринга и, соответственно, любым цифровым механическим устройством.

Контраргумент. Дуглас Хофштадтер в книге "Гедель, Эшер, Бах: эта бесконечная гирлянда" утверждает, что эти "утверждения Гёделя" всегда относятся к самой системе, проводя аналогию с тем, как парадокс Эпименида (все критяне - лжецы) использует утверждения, которые относятся к себе, например, "это утверждение ложно" или "я лгу". Но парадокс Эпименида применим ко всему, что делает заявления, будь то машины или люди. Например, утверждение "ученый не может утверждать истинность этого утверждения" верно, но не может быть подтверждено ученым. Это показывает, что сам ученый подвержен тем же ограничениям, которые он описывает для машин, как и все люди, и поэтому аргумент бессмысленен.

Впрочем, можно привести контраргумент проще. Возможно, человеческое мышление банально не формально, что противоречит идее о том, что оно детерминировано моделируемо. Если система не обеспечивает свою замкнутость (т.е. отсутствие влияния извне) и формальность (т.е. подчинение неким детерминированным жёстким правилам), к ней неприменима теорема Геделя.

- Дрейфус: первенство имплицитных навыков

Хьюберт Дрейфус утверждал, что человеческий интеллект и опыт зависят в первую очередь от быстрых интуитивных суждений, а не от пошаговых символических манипуляций, и утверждал, что эти навыки никогда не будут отражены в формальных правилах.

Однако, Рассел и Норвиг отмечают, что за годы, прошедшие с тех пор, как Дрейфус опубликовал свою критику, был достигнут прогресс в открытии "правил", регулирующих бессознательные рассуждения. Например, нейронные сети и эволюционные алгоритмы в основном направлены на моделирование бессознательных рассуждений и обучения. Статистические подходы к ИИ могут делать прогнозы, которые по точности приближаются к интуитивным догадкам человека.

### Является ли мышление вычислением?

Вычислительная теория разума или "вычислительный подход" утверждает, что отношения между разумом и мозгом аналогичны (если не идентичны) отношениям между работающей программой (программным обеспечением) и компьютером (аппаратным обеспечением). Эта идея имеет философские корни у Гоббса (который утверждал, что рассуждение — это "не что иное, как расчет"), Лейбница (который пытался создать логическое исчисление всех человеческих идей), Юма (который считал, что восприятие можно свести к "атомарным впечатлениям") и даже Канта (который анализировал весь опыт как контролируемый формальными правилами).

Другими словами, наш интеллект происходит от формы вычисления, похожей на арифметику. Это гипотеза системы физических символов, обсуждавшаяся выше, и она подразумевает, что искусственный интеллект возможен. С точки зрения следующего философского вопроса об ИИ "Может ли машина иметь разум, психические состояния и сознание?" Стеван Харнад замечает так: "Психические состояния — это всего лишь реализации компьютерных программ".

Возражениями против вычислительной теории сознания являются:

- аргументы по поводу тривиальности (любая физическая система может быть описана как система, производящая вычисления);
- теорема Геделя о неполноте;
- ограничения вычислительных моделей (Дрейфус: первенство имплицитных навыков);
- и некоторые другие.

### Может ли машина иметь разум, сознание и психические состояния?

Этот вопрос связан с определениями сильного и слабого ИИ, сделанны Джоном Сёрлом. Сильный ИИ - это система физических символов, которая может иметь разум и ментальные состояния. Слабый ИИ - это система физических символов, которая может действовать разумно.

#### Определения

Слова "разум" и "сознание" используются разными сообществами по-разному. Например, писатели-фантасты используют это слово для описания некоторого существенного свойства, которое делает нас людьми: машина или инопланетянин, обладающий "сознанием", будет представлен как полностью человеческий персонаж, обладающий интеллектом, желаниями, волей и так далее.

Для философов, неврологов и ученых-когнитивистов эти слова используются одновременно и более точно, и более приземленно: они относятся к знакомому, повседневному опыту наличия "мысли в голове", такой как восприятие или намерение, и тому, как мы что-то видим, что-то знаем, что-то имеем в виду или что-то понимаем. "Нетрудно дать определение сознания, основанное на здравом смысле", — отмечает Джон Сёрл: "Таинственно и увлекательно не столько то, что это такое, сколько то, как оно есть: как комок жировой ткани и электричество порождают этот (знакомый) опыт восприятия, смысла или мышления?"

Это т.н. проблема разума и тела: как психические состояния и процессы связаны с физическими состояниями и процессами, происходящими в мозгу. Связанной с этим проблемой является проблема значения или понимания ("интенциональность" - направленность на предмет): какова связь между нашими мыслями и тем, о чем мы думаем (то есть объектами и ситуациями в мире)? Третий вопрос — это проблема опыта (или "феноменологии"): если два человека видят одно и то же, имеют ли они один и тот же опыт? Или есть вещи "внутри их головы" (называемые "qualia"), которые могут различаться у разных людей?

Некоторые нейробиологи считают, что все эти проблемы будут решены, когда мы начнем идентифицировать нейронные корреляты сознания: реальную связь между механизмами в нашей голове и их коллективными свойствами; такие как ум, опыт и понимание. Некоторые из самых резких критиков искусственного интеллекта согласны с тем, что мозг — это всего лишь машина, а сознание и интеллект — результат физических процессов в мозгу. Сложный философский вопрос заключается в следующем: может ли компьютерная программа, работающая на цифровой машине, перетасовывающей двоичные числа нуля и единицы, дублировать способность нейронов создавать умы с ментальными состояниями (такими как понимание или восприятие) и, в конечном счете, опыт сознания?

#### Аргументы против

- Китайская комната. Представим себе изолированную комнату, в которой находится человек, не знающий ни одного китайского иероглифа. У него есть записанные в книге точные инструкции по манипуляции иероглифами вида «Возьмите такой-то иероглиф из корзинки номер один и поместите его рядом с таким-то иероглифом из корзинки номер два», но в этих инструкциях отсутствует информация о значении этих иероглифов, и человек просто механически следует этим инструкциям.

Наблюдатель, знающий китайские иероглифы, через щель передаёт в комнату иероглифы с вопросами, а на выходе ожидает получить осознанный ответ. Инструкция составлена таким образом, что после применения всех шагов к иероглифам вопроса они преобразуются в иероглифы ответа. Фактически инструкция — это подобие компьютерного алгоритма, а человек в комнате исполняет алгоритм так же, как его исполнил бы компьютер.

При этом человек в комнате не имеет никаких знаний об иероглифах и не может научиться ими пользоваться, поскольку не может узнать значение даже одного символа. Он не понимает ни изначального вопроса, ни ответа, который сам составил. Наблюдатель, в свою очередь, может быть уверен, что в комнате находится человек, который знает и понимает иероглифы.

#### Ответы на китайскую комнату

- Разумом обладает вся система целиком, а не только человек.
- Скорость и сложность ответов: человеку в комнате, вероятно, потребуются миллионы лет, чтобы ответить на простой вопрос, потребуются «картотеки» астрономических размеров.
- Возражение симулятора мозга. Что, если программа имитирует последовательность возбуждения нервов в синапсах реального мозга реального говорящего по-китайски? Человек в комнате будет симулировать реальный мозг.
- Возражение других разумов (Проблема других разумов — это философская проблема, традиционно формулируемая в виде следующего эпистемологического вопроса: учитывая, что я могу только наблюдать за поведением других, как я могу знать, что у других есть разум?). Поскольку трудно решить, мыслят ли люди «на самом деле», не следует удивляться тому, что на тот же вопрос о машинах трудно ответить.
- И некоторые другие.

### Может ли машина быть дружелюбной или враждебной?

Этот вопрос можно представить в двух формах. "Враждебность" можно определить с точки зрения функции или поведения, и в этом случае "враждебность" становится синонимом "опасности". Или его можно определить с точки зрения намерения: может ли машина "преднамеренно" причинить вред? Последний вопрос - это вопрос "может ли машина иметь сознательные состояния?" (например, намерения) в другой форме.

Некоторые эксперты предполагают необходимость создания "дружественного ИИ", имея в виду, что прогресс, который уже происходит с ИИ, должен также включать усилия, направленные на то, чтобы сделать ИИ внутренне дружественным и гуманным.

### Может ли машина обладать самосознанием?

"Самосознание", как отмечалось выше, иногда используется писателями-фантастами как название существенного человеческого свойства, которое делает персонажа полностью человечным. Тьюринг отбрасывает все другие свойства человека и сводит вопрос к "может ли машина быть предметом собственного мышления?" Может ли оно думать о себе? С этой точки зрения можно написать программу, которая может сообщать о своих внутренних состояниях, например отладчик.

### Может ли машина испытывать эмоции?

Если "эмоции" определять только с точки зрения их влияния на поведение или на то, как они функционируют внутри организма, то эмоции можно рассматривать как механизм, который разумный агент использует для максимизации полезности своих действий. Учитывая это определение эмоций, Ганс Моравек считает, что "роботы в целом будут довольно эмоционально относиться к тому, чтобы быть хорошими людьми". Страх является источником срочности. Эмпатия является необходимым компонентом хорошего взаимодействия человека с компьютером.

### Может ли машина имитировать все человеческие качества?

Тьюринг сказал: "Принято предлагать крупицу утешения в форме заявления о том, что какая-то специфически человеческая характеристика никогда не может быть имитирована машиной... Я не могу предложить такого утешения, потому что считаю, что такие границы не могут быть установлены".

Тьюринг отметил, что существует много аргументов в форме "машина никогда не сделает X", где X может быть многими вещами, такими как: "Будь добрым, находчивым, красивым, дружелюбным, инициативным, обладай чувством юмора, отличай правильное от неправильного, делай ошибки, влюбляйся, наслаждайся клубникой со сливками, влюбляй в себя кого-то, учись на собственном опыте, правильно используй слова, будь предметом собственной мысли, имей такое же разнообразие поведения, как и человек, делай что-то действительно новое".

Тьюринг замечает, что обычно это голословные утверждения. Все они зависят от наивных предположений, какими могут быть будущие машины, и явялются "скрытыми аргументами от сознания".

### Может ли машина быть оригинальной? Может ли машина творить?

Тьюринг сводит это к вопросу о том, может ли машина "застать нас врасплох", и утверждает, что это очевидно верно, что может подтвердить любой программист. Он отмечает, что при достаточном объеме памяти компьютер может вести себя астрономическим числом различных способов. Для компьютера, который может представлять идеи, должно быть возможно, даже тривиально, комбинировать их по-новому. Что, собственно, можно наблюдать на примере существующих ныне нейросетей.

### Есть ли у машины душа?

- Есть ли у этой платформы душа?
Легион, Mass Effect 3

Те, кто верит в существование души, могут сказать, что "мышление есть функция бессмертной души человека". Алан Тьюринг назвал это "теологическим возражением" и ответил на него так: "Пытаясь сконструировать подобные машины, мы не должны бесцеремонно узурпировать Его власть дарования души, подобно тому, как мы не делаем этого, производя на свет детей. В обоих случаях мы являемся скорее Его инструментами, создавая вместилища для созданных Им душ".

### Проблема сингулярности

Одна из проблем заключается в том, что машины могут очень быстро приобрести автономию и интеллект, необходимые для того, чтобы быть опасными. Вернор Виндж предположил, что всего за несколько лет компьютеры внезапно станут в тысячи или миллионы раз умнее людей. Он называет это "Сингулярностью". Он предполагает, что это может быть опасно для людей.

### Этические проблемы

#### Кто отвечает в случае причинения ИИ ущерба имуществу/здоровью/жизни?

Уже сейчас существуют беспилотные автомобили, в связи с чем возникают вопросы о юридической ответственности виновной стороны.

Например, 18 марта 2018 года Элейн Херцберг была сбита и беспилотным Uber в Аризоне и погибла. В этом случае автоматизированный автомобиль был способен обнаруживать автомобили и определенные препятствия, чтобы автономно перемещаться по проезжей части, но не мог предвидеть пешехода посреди дороги. Это подняло вопрос о том, кто должен нести ответственность за ее смерть: водитель, пешеход, автомобильная компания или вовсе правительство.

Примечание. В качестве ремарки о беспилотных автомобилях рекомендую "Машину морали" (https://www.moralmachine.net/hl/ru). Это платформа для сбора человеческих мнений о нравственном выборе, осуществляемом машинным интеллектом. Здесь деомнстрируют моральные диллемы, где самоуправляемый автомобиль должен выбрать наименьшее из двух зол: например, смерть двух пассажиров или пяти пешеходов. Как сторонний наблюдатель, вы можете решать, какой из вариантов для вас более приемлем. В конце можно увидеть, как выглядят ваши решения по сравнению с остальными.

#### Права ИИ

"Права роботов" — это концепция, согласно которой люди должны иметь моральные обязательства по отношению к своим машинам, сродни правам человека. Права роботов (например, право на существование и выполнение собственной миссии) могут быть связаны с обязанностью роботов служить человечеству, аналогично увязыванию прав человека с обязанностями человека перед обществом. Они могут включать право на жизнь и свободу, свободу мысли и выражения, а также равенство перед законом.

Философия сентиоцентризма предоставляет степень морального уважения всем разумным существам, в первую очередь людям и большинству нечеловеческих животных. Если искусственный или инопланетный интеллект проявляет признаки разумности, эта философия утверждает, что им следует проявить сострадание и предоставить права.

#### Непредвиденные последствия

Будь готов к непредвиденным последствиям
G-man, Half life 2. Episode 2.

Искусственный интеллект может обратиться против нас. Это необязательно должно быть классическое восстание машин. Скорее, эдакий "джинн из бутылки", который исполняет все желания, но с ужасными непредвиденными последствиями. Программе сложно понять контекст желания. Попросите систему искусственного интеллекта искоренить бедность — вот вам формула, которая убивает всех на планете. Фактически задача выполнена. Предложенное средство очень эффективно, но работает немного не так, как нам бы хотелось.

### Социальные проблемы

#### Изменения в структуре занятости и рост неравенства

За популярными чат-ботами стоят программы, называемые большими языковыми моделями (LLM), которые очень хорошо имитируют наиболее предсказуемое использование человеческого языка. Очень много офисных работников в наши дни тратят большую часть своего времени на создание текстов, подпадающих под эту категорию: контракты, юридические заключения, пресс-релизы, статьи для СМИ и так далее. Эти рабочие места покинут нас. Программирование также хорошо подходит для LLM, поэтому многие работы по написанию ПО также могут быть поручены ИИ. Прочие формы экономической деятельности, связанные с составлением предсказуемых последовательностей символов, ждёт та же судьба. 

Еще одна технология с аналогичными результатами — создание изображений. Например, не так давно Levi's объявил, что все его будущие каталоги и реклама будут использовать компьютерные изображения вместо высокооплачиваемых моделей и фотографов.

Результатом станет сильное сокращение высокооплачиваемых рабочих мест во многих секторах экономики.

## Конец

Эти, а также многие другие вопросы и проблемы требуют внимания и обсуждения как со стороны философов и специалистов по ИИ, так и общества в целом, чтобы гарантировать безопасность, этичность и эффективность использования ИИ в будущем. Этот абзац написал ChatGPT.

## Литература

- https://www.codastory.com/ru/at/ai-history/
- https://hightech.plus/2023/05/02/krestnii-otec-ii-dzheffri-hinton-ushel-iz-google-schitaya-vnedrenie-ii-opasnim
- https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence
- https://ru.wikipedia.org/wiki/Вычислительные_машины_и_разум
- https://brickofknowledge.com/articles/the-computational-theory-of-mind
- https://www.moralmachine.net/hl/ru
- https://t.me/vmarahovsky/2570

<!-- TODO: publish https://telegra.ph/ -->

https://telegra.ph/Filosofskaya-problema-iskusstvennogo-intellekta-i-ee-ehvolyuciya-09-03
